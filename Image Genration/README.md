# DCGAN - Image Generation
> [ğŸ”—Pytorch DCGAN ë²ˆì—­ ê°€ì´ë“œ]('https://tutorials.pytorch.kr/beginner/dcgan_faces_tutorial.html')    
[ğŸ”—ì´ë¯¸ì§€ íŒŒì¼ ì¶œì²˜ (Kaggle)](https://www.kaggle.com/datasets/erkamk/cat-and-dog-images-dataset) + [ğŸ”—PIXELS](https://www.pexels.com/search/cat/) ã€€ã€€<span style="color: grey"> Github ë¦¬í¬ì§€í† ë¦¬ì—ëŠ” ì¼ë¶€ë§Œ ì²¨ë¶€ </span>    
<pre>
<b>  ì‘ì—… í™˜ê²½ </b> 
OS      : Ubuntu Linux 20.04
CPU     : 8
Memory  : 64GB
GPU     : ë¹„í™œì„±í™”
</pre>

## ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
```python
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML

random_seed = 84
print("Random Seed: ", random_seed)
random.seed(random_seed)
torch.manual_seed(random_seed)
torch.use_deterministic_algorithms(True)
```
```python
# Hyper parameter
dataroot = "./cat_photo"    # ë°ì´í„°ì…‹ ê²½ë¡œ
workers = 8                 # ì“°ë ˆë“œ ê°¯ìˆ˜
batch_size = 32             # ë°°ì¹˜ ì‚¬ì´ì¦ˆ (í•œë²ˆì— ì½ì„ ì´ë¯¸ì§€ ìˆ˜)
image_size = 64             # ì´ë¯¸ì§€ í¬ê¸° (64í”½ì…€ë¡œ í†µì¼)
nc = 3                      # ì´ë¯¸ì§€ ì±„ë„ ìˆ˜ (RGB = 3)
nz = 30                     # ì…ë ¥ê°’ í¬ê¸°
ngf = 64                    # ìƒì„±ìì—ì„œ ë°ì´í„° ì±„ë„ í¬ê¸°
ndf = 32                    # êµ¬ë¶„ìì—ì„œ ë°ì´í„° ì±„ë„ í¬ê¸°
num_epochs = 54             # Epoch
lr_G = 0.0003               # ìƒì„±ìì˜ í•™ìŠµë¥ 
lr_D = 0.0002               # êµ¬ë¶„ìì˜ í•™ìŠµë¥ 
beta1 = 0.5                 # Adam ì˜µí‹°ë§ˆì´ì €ì˜ beta1 ê°’
ngpu = 1                    #gpu í™˜ê²½ì—ì„œ ì‚¬ìš©í•  ë•Œ GPUì˜ ê°œìˆ˜ ì§€ì •ê°€ëŠ¥
```
í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì´ë¯¸ì§€ ê°œìˆ˜ê°€ 527ê°œì´ë¯€ë¡œ ë°°ì¹˜ì‚¬ì´ì¦ˆëŠ” 32ë¡œ ì¤„ì´ê³  nzë„ ì¡°ì ˆí–ˆë‹¤.   
ì´í›„ í•™ìŠµ ê³¼ì •ì—ì„œ ìƒì„±ìì™€ êµ¬ë¶„ìì˜ lossê°’ì´ ë„ˆë¬´ í° ì°¨ì´ë¥¼ ë³´ì—¬ í•™ìŠµì´ ì›í™œí•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ngfì™€ ndfì— ì°¨ì´ë¥¼ ì£¼ê³  í•™ìŠµë¥ ì— ì°¨ì´ë¥¼ ì¤˜ ê· í˜•ìˆê²Œ í•™ìŠµí•˜ë„ë¡ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì ˆí–ˆë‹¤.   
ê·¸ ë’¤ dataloaderë¡œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë§Œë“ ë‹¤.
## ì‚¬ì§„ ë°ì´í„° ì¦ê°•
```python
dataset = dset.ImageFolder(root=dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                              #  transforms.RandomRotation(10),
                               transforms.ColorJitter(brightness=0.2, saturation=0.2),
                               transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 1.2)),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]))

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis('off')
plt.title("training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))
plt.show()
```
![training_image](./imge_generation_output/training_image.png)   

ì´ë¯¸ì§€ë¥¼ ë¶€ë¥¸ ë’¤ ë°ì´í„° ì¦ê°•ì„ í•´ì¤¬ë‹¤. ëª¨ë“  ì‚¬ì§„ì˜ í¬ê¸°ë¥¼ ë™ì¼í•˜ë„ë¡ ì¡°ì •í•˜ê³  Color Jitter, GaussianBlurë¥¼ ì ìš©í–ˆë‹¤. ê°ê° ì´ë¯¸ì§€ì˜ ë³´ì •ê°’ê³¼ íë¦¼ì„ ì¡°ì ˆí•˜ëŠ” ê²ƒì´ë‹¤.   
ì´ë¯¸ì§€ë¥¼ íšŒì „ì‹œí‚¤ëŠ” Rotationê³¼ Color Jitterì˜ ìƒ‰ì¡° ê´€ë ¨ ì¸ìëŠ” ì˜¤íˆë ¤ í•™ìŠµì„ ë°©í•´í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì—¬ ì œì™¸í–ˆë‹¤.
## ëª¨ë¸ êµ¬ì„±
```python
def weight_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)   # mean = 0, stdev = 0.02
    elif classname.find('CBatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)
```
ì •ê·œë¶„í¬ë¥¼ ì´ìš©í•´ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.
### ìƒì„±ì (Generator)
```python
class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),

            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()

        )
    def forward(self, input):
        return self.main(input)

netG = Generator(ngpu).to(device)

netG.apply(weight_init)

print(netG)
```
ìƒì„±ìëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•œë‹¤. í•™ìŠµëœ ì´ë¯¸ì§€ì—ì„œ ì–»ì€ ë²¡í„°ë¥¼ ë°ì´í„°ì™€ ë™ì¼í•œ í¬ê¸°ë¡œ ë³€í™˜í•´ ìœ ì‚¬í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤. ê° í•©ì„±ê³± ë ˆì´ì–´ë§ˆë‹¤ ì •ê·œí™”ì™€ ReLUë¥¼ ê±°ì¹œë‹¤. ì¶œë ¥ì€ Tanh í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚œë‹¤.
### êµ¬ë¶„ì
```python
class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.1, inplace=True),

            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.1, inplace=True),

            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.1, inplace=True),

            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.1, inplace=True),

            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

netD = Discriminator(ngpu).to(device)

if (device.type == "cuda") and (ngpu > 1):
    netD = nn.DataParallel(netD, list(range(ngpu)))

netD.apply(weight_init)

print(netD)
```
êµ¬ë¶„ìëŠ” ìƒì„±ìê°€ ì œëŒ€ë¡œ ëœ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆëŠ”ì§€ íŒŒì•…í•˜ëŠ” ì´ì§„ë¶„ë¥˜í•¨ìˆ˜ì´ë‹¤. êµ¬ë¶„ì ì—­ì‹œ ê¸°ê³„í•™ìŠµì„ ê±°ì¹œ ë’¤ ìƒì„±ìì—ì„œ ì¶œë ¥ëœ ì´ë¯¸ì§€ë¥¼ ê±°ì§“, ì°¸ìœ¼ë¡œ ë‚˜ëˆˆë‹¤. ë‘ ëª¨ë¸ì´ ì„œë¡œ ê²½ìŸí•˜ë©° ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì‹¤ì œì™€ ìµœëŒ€í•˜ê²Œ ìˆ˜ë ´í•˜ë„ë¡ í•™ìŠµì„ ê±°ì¹œë‹¤.
## ëª¨ë¸ í•™ìŠµ
### ì†ì‹¤í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
```python
criterion = nn.BCELoss()

fixed_noise = torch.randn(64, nz, 1, 1, device=device)

real_label = 1
fake_label = 0

optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, 0.999))
```
ì†ì‹¤ í•¨ìˆ˜ëŠ” BCELossë¡œ í•˜ê³  ì˜µí‹°ë§ˆì´ì €ëŠ” Adamìœ¼ë¡œ ë§ì¶˜ë‹¤. í•™ìŠµë¥ ì€ ìƒì„±ìì™€ êµ¬ë¶„ì ê°ê° ë”°ë¡œ ë§ì¶˜ë‹¤. 
### í•™ìŠµ
```python
img_list = []
G_losses = []
D_losses = []
iters = 0

print("ğŸƒâ€â™‚ï¸Starting Training Loop...")
for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):

        ### D ì‹ ê²½ë§ ì—…ë°ì´íŠ¸
        #ì§„ì§œ ì´ë¯¸ì§€ë¡œ í•™ìŠµ
        netD.zero_grad()

        real_cpu = data[0].to(device)
        b_size = real_cpu.size(0)
        label = torch.full((b_size,), real_label,
                            dtype=torch.float, device=device)
        output = netD(real_cpu).view(-1)
        errD_real = criterion(output, label)
        
        errD_real.backward()
        D_x = output.mean().item()

        #ê°€ì§œ ì´ë¯¸ì§€ë¡œ í•™ìŠµ
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        
        fake = netG(noise)
        label.fill_(fake_label)

        output = netD(fake.detach()).view(-1) #detachëŠ” gradient ê³„ì‚°ì— ì´ìš©ë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” í•¨ìˆ˜ (ì¤‘ê°„ê°’ ì¶œë ¥ì— ì´ìš©)
        errD_fake = criterion(output, label)
        errD_fake.backward()
        D_G_z1 = output.mean().item()

        errD = errD_real + errD_fake

        optimizerD.step()

        ### G ì‹ ê²½ë§ ì—…ë°ì´íŠ¸
        netG.zero_grad()
        label.fill_(real_label)

        output = netD(fake).view(-1)
        errG = criterion(output, label)
        errG.backward()
        D_G_z2 = output.mean().item()

        optimizerG.step()

        #í›ˆë ¨ ìƒíƒœ ì¶œë ¥
        if i % 5 == 0:
            print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
                % (epoch, num_epochs, i, len(dataloader),
                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))
        
        G_losses.append(errG.item())
        D_losses.append(errD.item())

        if (iters % 55 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader)-1)):
            with torch.no_grad():
                fake = netG(fixed_noise).detach().cpu()
            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))
        iters += 1
print('ğŸš©Training Finished')
```
![alt text](./imge_generation_output/loss.png)

í•™ìŠµ ì¤‘ ì†ì‹¤ê°’ ë³€í™”ëŠ” ìœ„ì²˜ëŸ¼ ë‚˜íƒ€ë‚œë‹¤. ìƒì„±ìì™€ êµ¬ë¶„ìì˜ Lossê°€ ë¹„ìŠ·í•œ ê²ƒì´ ê°€ì¥ ì´ìƒì ì¸ í˜•íƒœë¼ê³  í•˜ì§€ë§Œ ì´ë¯¸ì§€ ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šì•„ êµ¬ë¶„ìê°€ ì•½ê°„ ë” ìœ ë¦¬í•˜ë„ë¡ í–ˆë‹¤. 

### ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼
![alt text](./imge_generation_output/3rd_output_ndf_lr.png)
ì™¼ìª½ì€ ì‹¤ì œ í•™ìŠµëœ ì´ë¯¸ì§€ ì˜¤ë¥¸ìª½ì€ ìƒì„±ëœ ì´ë¯¸ì§€ì´ë‹¤. ê³ ì–‘ì´ì˜ í˜•íƒœë¼ê³  ë³´ê¸° í˜ë“¤ê²Œ êµ¬ê²¨ì§„ í˜•íƒœë§Œ ë³´ì´ê³  ìˆë‹¤. í•˜ì§€ë§Œ ì ì€ ë°ì´í„°ì„ì—ë„ ìƒ‰ê¹”ì´ë‚˜ í˜•íƒœë¡œ ë³´ì•„ í”¼ì‚¬ì²´ì™€ ë°°ê²½ì„ êµ¬ë¶„í•˜ë ¤ê³  í•˜ëŠ” ì–‘ìƒì„ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.