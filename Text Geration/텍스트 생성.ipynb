{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 생성\n",
    "Winnie the Pooh 텍스트 파일을 이용한 학습  \n",
    "https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, '[': 29, ']': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57, 'æ': 58, '—': 59, '‘': 60, '’': 61, '“': 62, '”': 63, '•': 64, '™': 65}\n",
      "Total Characters:  148066\n",
      "Total Vocab:  66\n"
     ]
    }
   ],
   "source": [
    "# 파일 읽기, 소문자로 변환\n",
    "file_name ='./Winnie-the-Pooh.txt'\n",
    "raw_text = open(file_name, 'r', encoding='utf-8').read()\n",
    "lower_text = raw_text.lower()\n",
    "\n",
    "# chars -> integer mapping\n",
    "chars = sorted(list(set(lower_text))) \n",
    "chars_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "print(chars_to_int) #파일 내에 있는 고유 문자를 단어사전으로 저장함\n",
    "\n",
    "\n",
    "\n",
    "n_chars = len(lower_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  147966\n"
     ]
    }
   ],
   "source": [
    "seq_len = 100 #101자로 나눠서 학습, 예측을 수행함\n",
    "X_data = []\n",
    "Y_data = []\n",
    "for i in range(0, n_chars - seq_len, 1):\n",
    "    seq_in = lower_text[i:i + seq_len]\n",
    "    seq_out = lower_text[i + seq_len]\n",
    "    X_data.append([chars_to_int[c] for c in seq_in])\n",
    "    Y_data.append(chars_to_int[seq_out])\n",
    "n_patterns = len(X_data)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([147966, 100, 1]) torch.Size([147966])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(X_data, dtype=torch.float32).reshape(n_patterns, seq_len, 1) #tensor를 통해 각 문자들을 나눔\n",
    "X = X / float(n_vocab) #vocab수로 나눠서 정규화 (0-1로 만듦 <- Pytorch는 0~1 값 선호)\n",
    "y = torch.tensor(Y_data)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(256, n_vocab)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.linear(self.dropout(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cross-entrophy: 422362.9688\n",
      "Epoch 1: Cross-entrophy: 405260.9375\n",
      "Epoch 2: Cross-entrophy: 389037.4688\n",
      "Epoch 3: Cross-entrophy: 376983.3438\n",
      "Epoch 4: Cross-entrophy: 367182.5312\n",
      "Epoch 5: Cross-entrophy: 358907.2500\n",
      "Epoch 6: Cross-entrophy: 351417.1875\n",
      "Epoch 7: Cross-entrophy: 341741.1562\n",
      "Epoch 8: Cross-entrophy: 334116.6875\n",
      "Epoch 9: Cross-entrophy: 328914.7500\n",
      "Epoch 10: Cross-entrophy: 321809.8125\n",
      "Epoch 11: Cross-entrophy: 317064.7812\n",
      "Epoch 12: Cross-entrophy: 308550.7812\n",
      "Epoch 13: Cross-entrophy: 303386.5312\n",
      "Epoch 14: Cross-entrophy: 297692.3125\n",
      "Epoch 15: Cross-entrophy: 292292.9375\n",
      "Epoch 16: Cross-entrophy: 288756.2500\n",
      "Epoch 17: Cross-entrophy: 282903.8750\n",
      "Epoch 18: Cross-entrophy: 279991.3750\n",
      "Epoch 19: Cross-entrophy: 274500.4062\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 128\n",
    "model = BuildModel()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "loader = data.DataLoader(data.TensorDataset(X, y), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():                   #학습을 멈추고 모델 평가 (validation)\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss += loss_fn(y_pred, y_batch)\n",
    "        if loss < best_loss:                #현재 저장된 loss보다 저 작게 나오면 모델 저장\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print('Epoch %d: Cross-entrophy: %.4f' % (epoch, loss))\n",
    "\n",
    "torch.save([best_model, chars_to_int], \"./model_checkpoints/text_generator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      " balloon?\"\n",
      "\n",
      "\"yes, i just said to myself coming along: 'i wonder if christopher robin\n",
      "has such a thing  _____\n",
      " and then the boll hs toe tore \n",
      "\n",
      "\"ioo the tooe   \"a larpy hirteey,\" \n",
      "\"yhs, yhu kave ho in \" \n",
      "\"the oor toe lo the hertoon \" \n",
      "\"yhs, yhu iave g vorl ho in an hnnettor b aoa oo ho so bo the bootoe \" \n",
      "\"the oere po he poe\"thre \" soo tere airistopher robin sas shit the borto tf the pore of the sore of the horest, \n",
      "\"io whu den tooh \" \n",
      "\"yhet so he soo to lave a lort of toeek to an toeetllng \"\n",
      "\n",
      "\"that so he soo tool \" \n",
      "\"yhs  bedrueey _ dare if io \" said thbnit  \"io i soele to toell to soeethin \" \n",
      "\"yhut ao the btruon oo the tore \" said pooh. \n",
      "\"th toal i yout oo tee horert?\" \n",
      "\"yes, \n",
      "\n",
      "\"i shsught to he c derroon \" said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou tee woul   said pooh.\n",
      "\n",
      "\"io sou t\n",
      "__Fin__\n"
     ]
    }
   ],
   "source": [
    "best_model, chars_to_int = torch.load(\"./model_checkpoints/text_generator.pth\")\n",
    "n_vocab = len(chars_to_int)\n",
    "int_to_chars = dict((i, c) for c, i in chars_to_int.items())\n",
    "\n",
    "start = np.random.randint(0, len(raw_text)-seq_len)\n",
    "prompt = lower_text[start:start+seq_len]            #문서 중 문구를 랜덤으로 뽑아서 seq_length 만큼 프롬프트로 입력\n",
    "pattern = [chars_to_int[c] for c in prompt]\n",
    "\n",
    "model.eval()\n",
    "print(\"Prompt: \\n %s  _____\" % prompt)\n",
    "with torch.no_grad():\n",
    "    for i in range(1000):           #모델을 1000번 반복함. 즉 글자수가 1000이 될때까지 텍스트를 생성\n",
    "        # 입력을 tensor로\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1)) / float(n_vocab)\n",
    "        x = torch.tensor(x, dtype = torch.float32)\n",
    "\n",
    "        # 문자 logit 계산\n",
    "        prediction = model(x)\n",
    "\n",
    "        # 인덱스를 문자로 변환\n",
    "        index = int(prediction.argmax())\n",
    "        result = int_to_chars[index]\n",
    "        print(result, end = \"\")\n",
    "\n",
    "        # 프롬프트에 단어를 추가\n",
    "        pattern.append(index)\n",
    "        pattern=pattern[1:]\n",
    "print()\n",
    "print(\"__Fin__\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
